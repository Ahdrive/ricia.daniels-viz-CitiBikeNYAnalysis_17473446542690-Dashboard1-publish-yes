{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_2022_1 = pd.read_csv(\"Data/202205-citibike-tripdata_1.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "may_2022_2 = pd.read_csv(\"Data/202205-citibike-tripdata_2.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "may_2022_3 = pd.read_csv(\"Data/202205-citibike-tripdata_3.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "jun_2022_1 = pd.read_csv(\"Data/202206-citibike-tripdata_1.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "jun_2022_2 = pd.read_csv(\"Data/202206-citibike-tripdata_2.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "jun_2022_3 = pd.read_csv(\"Data/202206-citibike-tripdata_3.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "jun_2022_4 = pd.read_csv(\"Data/202206-citibike-tripdata_4.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "may_2023_1 = pd.read_csv(\"Data/202305-citibike-tripdata_1.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "may_2023_2 = pd.read_csv(\"Data/202305-citibike-tripdata_2.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "may_2023_3 = pd.read_csv(\"Data/202305-citibike-tripdata_3.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "may_2023_4 = pd.read_csv(\"Data/202305-citibike-tripdata_4.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "jun_2023_1 = pd.read_csv(\"Data/202306-citibike-tripdata_1.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "jun_2023_2 = pd.read_csv(\"Data/202306-citibike-tripdata_2.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "jun_2023_3 = pd.read_csv(\"Data/202306-citibike-tripdata_3.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "jun_2023_4 = pd.read_csv(\"Data/202306-citibike-tripdata_4.csv\", dtype={'start_station_id': str, 'end_station_id': str})\n",
    "\n",
    "may_2022_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df = pd.concat([may_2022_1,may_2022_2,may_2022_3,jun_2022_1,jun_2022_2,jun_2022_3,jun_2022_4, may_2023_1,may_2023_2,may_2023_3,may_2023_4,jun_2023_1,jun_2023_2,jun_2023_3,jun_2023_4])\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df.drop(columns=['ride_id', 'ended_at', 'start_station_id', 'end_station_id', 'member_casual'], inplace=True)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df = combined_df.rename(columns={'rideable_type': 'Ridable Type', 'started_at': 'Date', 'start_station_name': 'Start Station', 'end_station_name': 'End Station', 'start_lat': 'Start Lat', 'start_lng': 'Start Lon', 'end_lat': 'End Lat', 'end_lng': 'End Lon'})\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"Trip Year\"] = combined_df[\"Date\"].str.split(\"-\", expand=True)[0]\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['TripMonth'] = combined_df[\"Date\"].str.split(\"-\", expand=True)[1]\n",
    "#combined_df.head()\n",
    "\n",
    "combined_df['Trip Month'] = combined_df[\"TripMonth\"].replace({\"05\": \"May\", \"06\": \"June\"}) \n",
    "#combined_df.head()\n",
    "\n",
    "combined_df.drop(columns=['TripMonth'], inplace=True)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = combined_df['Ridable Type'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Type'] = combined_df[\"Ridable Type\"].replace({\"classic_bike\": \"Classic Bike\", \"electric_bike\": \"Electric Bike\"}) \n",
    "#combined_df.head()\n",
    "\n",
    "combined_df.drop(columns=['Ridable Type'], inplace=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove bad data rows\n",
    "#unique_months = combined_df['Trip Month'].unique();\n",
    "#print(unique_months)\n",
    "# Conditions\n",
    "#condition1 = combined_df['Trip Month'] == 'May'\n",
    "#condition2 = combined_df['Trip Month'] == 'June'\n",
    "\n",
    "# Combine conditions using logical operators (&, |, ~)\n",
    "#combined_condition = condition1 | condition2\n",
    "\n",
    "# Remove rows that satisfy the combined condition\n",
    "#df_filtered = combined_df[combined_condition]\n",
    "#df_filtered.head()\n",
    "\n",
    "unique_months = combined_df['Trip Month'].unique();\n",
    "print(unique_months)\n",
    "# Conditions\n",
    "condition1 = combined_df['Trip Month'] == '04'\n",
    "condition2 = combined_df['Trip Month'] == '03'\n",
    "condition3 = combined_df['Trip Month'] == '01'\n",
    "condition4 = combined_df['Trip Month'] == '11'\n",
    "condition5 = combined_df['Trip Month'] == '02'\n",
    "condition6 = combined_df['Trip Month'] == '07'\n",
    "condition7 = combined_df['Trip Month'] == '08'\n",
    "condition8 = combined_df['Trip Month'] == '09'\n",
    "condition9 = combined_df['Trip Year'] == '2021'\n",
    "\n",
    "# Combine conditions using logical operators (&, |, ~)\n",
    "combined_condition = condition1 | condition2 | condition3 | condition4 | condition5 | condition6 | condition7 | condition8 | condition9\n",
    "\n",
    "# Remove rows that satisfy the combined condition\n",
    "df_filtered = combined_df[~combined_condition]\n",
    "print(len(combined_df))\n",
    "print(len(df_filtered))\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(r'Data/clean_df.csv')\n",
    "print(len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
